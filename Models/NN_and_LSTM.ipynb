{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Este código se corrio desde google drive, si se planea correr desde una laptop, cambiar la función de lectura de datos\n",
        "\n",
        "Para la obtención de los 6 modelos 3 de nn y 3 de lstm, se corrio este código 3 veces, cambiando el nombre del dataset seleccionado y el nombre con el que se guarda el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnLz_AaZAyIw",
        "outputId": "5920d56c-de45-484a-99ab-fffa1ea5d7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOCrNMWXA-19",
        "outputId": "2496ef4a-42f9-407b-ccb2-d16a95860a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/Shareddrives/Funados x el KIKE/Reto\n",
            "'Comparación modelos.gsheet'   LSTM_labels_clean.h5  'Untitled0 (1).ipynb'\n",
            " labels_clean.csv\t       NN_labels_clean.h5     Untitled0.ipynb\n",
            " labels_tokenized.csv\t       nuevo_labels.csv\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/gdrive/Shareddrives/Funados x el KIKE/Reto\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMlASjE3BCTw",
        "outputId": "3dad2b10-267f-4033-fafd-0c75b751b912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - 1s 23ms/step - loss: 29.9070 - accuracy: 0.6058 - val_loss: 9.9507 - val_accuracy: 0.6838\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 0s 20ms/step - loss: 3.5089 - accuracy: 0.7519 - val_loss: 7.8180 - val_accuracy: 0.6838\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 0s 18ms/step - loss: 0.9574 - accuracy: 0.8737 - val_loss: 9.2884 - val_accuracy: 0.7094\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 0s 19ms/step - loss: 0.3365 - accuracy: 0.9376 - val_loss: 8.3119 - val_accuracy: 0.7094\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 0s 19ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 7.9183 - val_accuracy: 0.6923\n",
            "Epoch 6/10\n",
            "21/21 [==============================] - 0s 19ms/step - loss: 0.0222 - accuracy: 0.9909 - val_loss: 7.9313 - val_accuracy: 0.6581\n",
            "Epoch 7/10\n",
            "21/21 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 7.8945 - val_accuracy: 0.6838\n",
            "Epoch 8/10\n",
            "21/21 [==============================] - 0s 17ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 8.0246 - val_accuracy: 0.6581\n",
            "Epoch 9/10\n",
            "21/21 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 7.8930 - val_accuracy: 0.6581\n",
            "Epoch 10/10\n",
            "21/21 [==============================] - 0s 20ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 7.9096 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57080d0ee0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "data = pd.read_csv('nuevo_labels.csv')\n",
        "\n",
        "X = data[['sub1', 'sub2']]\n",
        "y = data['verdict']\n",
        "\n",
        "# Tokenizar y convertir los textos en secuencias numéricas\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X['sub1'] + ' ' + X['sub2'])\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(X['sub1'] + ' ' + X['sub2'])\n",
        "\n",
        "# Rellenar las secuencias para que todas tengan la misma longitud\n",
        "max_len = max([len(seq) for seq in X_sequences])\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_len)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_padded, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(64, activation='relu', input_shape=(max_len,)))\n",
        "modelo.add(Dense(32, activation='relu'))\n",
        "modelo.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qtz8KWEPoYo"
      },
      "outputs": [],
      "source": [
        "modelo.save(\"NN_nuevo_labels.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPao_l3nBDUm",
        "outputId": "137b2ce7-b033-4a34-82e2-4127404c27c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 6ms/step\n",
            "Precisión del modelo (Prueba): 68.61%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en los datos de prueba\n",
        "y_pred = modelo.predict(X_test)\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo (Prueba): %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCOupj3sBHpU",
        "outputId": "dd8c522d-182a-4403-d5f5-fa2b48c42773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 0s 4ms/step\n",
            "Precisión del modelo (Entrenamiento): 95.74%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en los datos de entrenamiento\n",
        "y_train_pred = modelo.predict(X_train)\n",
        "y_train_pred = np.round(y_train_pred).flatten()\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Precisión del modelo (Entrenamiento): %.2f%%\" % (train_accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSRu_paVBQcy",
        "outputId": "44ed1b33-2fc9-4574-ccf3-da8e4fb83970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - 317s 15s/step - loss: 0.6214 - accuracy: 0.7139 - val_loss: 0.5961 - val_accuracy: 0.7179\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 305s 15s/step - loss: 0.5844 - accuracy: 0.7245 - val_loss: 0.5922 - val_accuracy: 0.7179\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 305s 15s/step - loss: 0.5657 - accuracy: 0.7245 - val_loss: 0.5984 - val_accuracy: 0.7179\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 310s 15s/step - loss: 0.5401 - accuracy: 0.7367 - val_loss: 0.6026 - val_accuracy: 0.7094\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 307s 15s/step - loss: 0.4945 - accuracy: 0.7839 - val_loss: 0.6154 - val_accuracy: 0.7009\n",
            "Epoch 6/10\n",
            "21/21 [==============================] - 306s 15s/step - loss: 0.4412 - accuracy: 0.8128 - val_loss: 0.6493 - val_accuracy: 0.7265\n",
            "Epoch 7/10\n",
            "21/21 [==============================] - 306s 15s/step - loss: 0.4293 - accuracy: 0.8219 - val_loss: 0.6747 - val_accuracy: 0.7009\n",
            "Epoch 8/10\n",
            "21/21 [==============================] - 309s 15s/step - loss: 0.3944 - accuracy: 0.8356 - val_loss: 0.6733 - val_accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "21/21 [==============================] - 309s 15s/step - loss: 0.3681 - accuracy: 0.8402 - val_loss: 0.7499 - val_accuracy: 0.7179\n",
            "Epoch 10/10\n",
            "21/21 [==============================] - 305s 15s/step - loss: 0.3745 - accuracy: 0.8493 - val_loss: 0.7396 - val_accuracy: 0.7094\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56f9fef3d0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "data = pd.read_csv('nuevo_labels.csv')\n",
        "\n",
        "X = data[['sub1', 'sub2']]\n",
        "y = data['verdict']\n",
        "\n",
        "# Tokenizar y convertir los textos en secuencias numéricas\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X['sub1'] + ' ' + X['sub2'])\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(X['sub1'] + ' ' + X['sub2'])\n",
        "\n",
        "# Rellenar las secuencias para que todas tengan la misma longitud\n",
        "max_len = max([len(seq) for seq in X_sequences])\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_len)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_padded, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "modelo1 = Sequential()\n",
        "modelo1.add(Embedding(len(tokenizer.word_index) + 1, 64, input_length=max_len))\n",
        "modelo1.add(LSTM(64))\n",
        "modelo1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo1.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo1.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R7WVR9PBZQY",
        "outputId": "c0b9634e-43c9-4f58-c48e-adc4bd73386f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 1s/step\n",
            "Precisión del modelo (Prueba): 66.42%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en los datos de prueba\n",
        "y_pred = modelo1.predict(X_test)\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo (Prueba): %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbk88SuKBbXy",
        "outputId": "8f16a36f-96d8-430b-803c-0e47721cbe23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 31s 1s/step\n",
            "Precisión del modelo (Entrenamiento): 82.95%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en los datos de entrenamiento\n",
        "y_train_pred = modelo1.predict(X_train)\n",
        "y_train_pred = np.round(y_train_pred).flatten()\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Precisión del modelo (Entrenamiento): %.2f%%\" % (train_accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuzLN5a7CLzh"
      },
      "outputs": [],
      "source": [
        "modelo1.save(\"LSTM_nuevo_labels.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZQ--XbzPkNX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
